# Dr. NewsForge's Advanced MLOps Configuration
# Enterprise-grade AI News Dashboard with continuous learning and deployment

project:
  name: "ai-news-dashboard"
  version: "2.0.0"
  description: "Advanced AI-powered news aggregation and analysis platform"
  maintainer: "Dr. Nova NewsForge Arclight"

# Model Registry and Versioning
model_registry:
  backend: "mlflow"
  tracking_uri: "http://localhost:5000"
  experiment_name: "news-ai-models"
  model_store: "s3://newsforge-models/"
  
  models:
    summarization:
      name: "news-summarizer"
      framework: "transformers"
      base_model: "facebook/bart-large-cnn"
      version: "1.2.0"
      performance_threshold: 0.85
      
    classification:
      name: "topic-classifier"
      framework: "transformers"
      base_model: "microsoft/DialoGPT-medium"
      version: "1.1.0"
      performance_threshold: 0.90
      
    sentiment:
      name: "sentiment-analyzer"
      framework: "transformers"
      base_model: "cardiffnlp/twitter-roberta-base-sentiment-latest"
      version: "1.0.0"
      performance_threshold: 0.88
      
    embedding:
      name: "news-embedder"
      framework: "sentence-transformers"
      base_model: "all-MiniLM-L6-v2"
      version: "1.0.0"
      performance_threshold: 0.82

# Continuous Integration/Continuous Deployment
ci_cd:
  platform: "github-actions"
  
  triggers:
    - push_to_main
    - pull_request
    - scheduled_daily
    - model_drift_detected
    
  stages:
    data_validation:
      enabled: true
      tests:
        - schema_validation
        - data_quality_checks
        - drift_detection
        
    model_training:
      enabled: true
      compute:
        instance_type: "ml.p3.2xlarge"
        max_runtime: "3600s"
      hyperparameter_tuning:
        enabled: true
        max_trials: 20
        
    model_evaluation:
      enabled: true
      metrics:
        - accuracy
        - f1_score
        - rouge_score
        - latency
        - throughput
      thresholds:
        min_accuracy: 0.85
        max_latency_ms: 100
        
    deployment:
      strategy: "blue-green"
      environments:
        - staging
        - production
      rollback_enabled: true
      canary_percentage: 10

# Monitoring and Observability
monitoring:
  prometheus:
    enabled: true
    port: 9090
    scrape_interval: "15s"
    
  grafana:
    enabled: true
    port: 3001
    dashboards:
      - model_performance
      - system_metrics
      - business_metrics
      
  alerting:
    slack_webhook: "${SLACK_WEBHOOK_URL}"
    email_recipients:
      - "alerts@newsforge.ai"
    
    rules:
      - name: "model_drift"
        condition: "drift_score > 0.1"
        severity: "warning"
        
      - name: "high_latency"
        condition: "avg_latency > 200ms"
        severity: "critical"
        
      - name: "low_accuracy"
        condition: "accuracy < 0.8"
        severity: "critical"

# Data Pipeline Configuration
data_pipeline:
  ingestion:
    batch_size: 1000
    frequency: "*/15 * * * *"  # Every 15 minutes
    sources:
      - rss_feeds
      - news_apis
      - social_media
      - web_scraping
      
  preprocessing:
    steps:
      - text_cleaning
      - language_detection
      - deduplication
      - quality_filtering
      
  feature_engineering:
    enabled: true
    features:
      - tfidf_vectors
      - bert_embeddings
      - sentiment_scores
      - readability_metrics
      
  storage:
    raw_data: "s3://newsforge-data/raw/"
    processed_data: "s3://newsforge-data/processed/"
    features: "s3://newsforge-data/features/"
    
# Vector Database Configuration
vector_db:
  provider: "pinecone"
  index_name: "news-embeddings"
  dimension: 384
  metric: "cosine"
  
  settings:
    replicas: 2
    shards: 1
    pod_type: "p1.x1"
    
# Federated Learning Configuration
federated_learning:
  enabled: true
  framework: "flower"
  
  server:
    host: "0.0.0.0"
    port: 8080
    rounds: 10
    min_clients: 3
    
  client:
    local_epochs: 5
    batch_size: 32
    learning_rate: 0.001
    
  privacy:
    differential_privacy: true
    noise_multiplier: 1.1
    max_grad_norm: 1.0

# Security and Compliance
security:
  authentication:
    method: "oauth2"
    provider: "auth0"
    
  authorization:
    rbac_enabled: true
    roles:
      - admin
      - data_scientist
      - analyst
      - viewer
      
  encryption:
    at_rest: true
    in_transit: true
    key_management: "aws-kms"
    
  compliance:
    frameworks:
      - "NIST-AI-RMF"
      - "GDPR"
      - "SOC2"
    
    audit_logging: true
    data_retention_days: 365

# Performance Optimization
performance:
  caching:
    redis:
      enabled: true
      host: "localhost"
      port: 6379
      ttl: 3600
      
  model_optimization:
    quantization: true
    pruning: false
    distillation: true
    
  inference:
    batch_size: 16
    max_workers: 4
    gpu_enabled: true
    
  auto_scaling:
    enabled: true
    min_replicas: 2
    max_replicas: 10
    target_cpu: 70
    target_memory: 80

# Environment Configuration
environments:
  development:
    debug: true
    log_level: "DEBUG"
    model_cache: false
    
  staging:
    debug: false
    log_level: "INFO"
    model_cache: true
    
  production:
    debug: false
    log_level: "WARNING"
    model_cache: true
    high_availability: true
    
# Backup and Recovery
backup:
  enabled: true
  frequency: "daily"
  retention_days: 30
  
  targets:
    - models
    - data
    - configurations
    
  storage: "s3://newsforge-backups/"
  
  disaster_recovery:
    rpo_hours: 4  # Recovery Point Objective
    rto_hours: 1  # Recovery Time Objective
    
# Resource Limits
resources:
  cpu_limit: "2000m"
  memory_limit: "4Gi"
  storage_limit: "100Gi"
  
  gpu:
    enabled: true
    type: "nvidia-tesla-v100"
    memory: "16Gi"